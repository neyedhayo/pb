{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a935a30",
   "metadata": {},
   "source": [
    "# Central Differential Privacy (Client-Side Clipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central Differential Privacy (Client-Side Clipping) is a setup where the clipping of model updates happens on each client before sending the updates to the central server. After collecting all the clipped updates, the server aggregates them and adds noise centrally to enforce differential privacy.\n",
    "\n",
    "In this setup:\n",
    "\n",
    "- Clipping happens locally on the client â€” helping reduce the influence of outlier updates early.\n",
    "\n",
    "- Noise is added by the server â€” simplifying coordination of privacy guarantees.\n",
    "\n",
    "The specific strategy used here is:\n",
    "\n",
    "## ViT: DifferentialPrivacyClientSideAdaptiveClipping\n",
    "\n",
    "This strategy uses adaptive gradient clipping on the client side, allowing each client to dynamically adjust its clipping norm based on recent gradient statistics. Rather than enforcing a fixed global threshold, clients estimate suitable clipping bounds (e.g., via moving averages of gradient norms) to better match the scale of their local updates. This makes the differential privacy mechanism more data-aware, potentially improving model utility while still maintaining rigorous privacy guarantees during federated aggregation.\n",
    "\n",
    "<br><p>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ce627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.11\n",
      "IPython version      : 9.1.0\n",
      "\n",
      "torch: 2.6.0\n",
      "flwr : 1.19.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext watermark\n",
    "    \n",
    "%autoreload 2\n",
    "%watermark --python -p torch,flwr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e5fd1",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dad519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import ray\n",
    "import time\n",
    "\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "from logging import ERROR\n",
    "\n",
    "from flwr.common import ndarrays_to_parameters, Context \n",
    "from flwr.client import Client, ClientApp\n",
    "from flwr.client.mod import adaptiveclipping_mod\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import DifferentialPrivacyClientSideAdaptiveClipping, FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "\n",
    "from src.config import ExperimentName\n",
    "from src.paths import RAY_LOG_DIR\n",
    "from src.FL_client import MedicalImageClient\n",
    "from src.FL_server import weighted_average, build_evaluate_fn\n",
    "from src.local_utility import load_yaml_config, set_device, prepare_FL_dataset, get_weights\n",
    "\n",
    "from src.tracker import reset_base_memory_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0033f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with appropritate values\n",
    "\n",
    "data_name_ = 'alzheimer' #\"skin_lesions\" #\n",
    "base_type_ = \"VIT\"           \n",
    "exp_name_ = \"CDP-CA\"\n",
    "num_labels_ = 4\n",
    "experiment_name_ = ExperimentName.FL_CDP_CA_VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c135ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = set_device()\n",
    "reset_base_memory_csv() \n",
    "\n",
    "fed_config = load_yaml_config(key=\"experiments\", item_name=experiment_name_)\n",
    "client_dataloaders = prepare_FL_dataset(exp_name= exp_name_, data_name=data_name_, base_type=base_type_, augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"\n",
    "    Creates and initializes a federated learning client.\n",
    "\n",
    "    This function initializes a client in the federated learning setup by \n",
    "    assigning a unique partitioned dataset and a machine learning model \n",
    "    for training and validation.\n",
    "\n",
    "    Args:\n",
    "        context (Context): The execution context containing client-specific configurations.\n",
    "\n",
    "    Returns:\n",
    "        Client: A configured federated learning client ready to participate in training.\n",
    "    \"\"\"\n",
    "    partition_id = int(context.node_config[\"partition-id\"]) #<--- Get the client partition ID\n",
    "    \n",
    "    model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", \n",
    "                                                      num_labels=num_labels_, \n",
    "                                                      ignore_mismatched_sizes=True\n",
    "                                                      )\n",
    "\n",
    "    # Assign partitioned client dataset\n",
    "    train_loader, val_loader, test_loader = client_dataloaders[partition_id]\n",
    "    \n",
    "    return MedicalImageClient(model, train_loader, val_loader, exp_name=exp_name_, data_name = data_name_, base_type=base_type_, client_id=partition_id).to_client()\n",
    "\n",
    "client = ClientApp(client_fn, mods=[adaptiveclipping_mod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8dc4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context):\n",
    "    \"\"\"\n",
    "    Creates and configures the federated learning server using the FedAvg strategy.\n",
    "\n",
    "    This function initializes the federated learning server with a FedAvg strategy,\n",
    "    specifying the parameters for client participation in training and evaluation,\n",
    "    the global model evaluation function, and the metric aggregation function.\n",
    "\n",
    "    Args:\n",
    "        context (Context): The execution context for the federated learning server.\n",
    "\n",
    "    Returns:\n",
    "        ServerAppComponents: A configured server application with the defined strategy\n",
    "        and server settings.\n",
    "    \"\"\"\n",
    "    model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", \n",
    "                                                      num_labels=num_labels_, \n",
    "                                                      ignore_mismatched_sizes=True\n",
    "                                                      )\n",
    "    params = ndarrays_to_parameters(get_weights(model))\n",
    "    \n",
    "    # Create FedAvg strategy\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0,                 #<--- Sample 100% of available clients for training\n",
    "        fraction_evaluate=1.0,            #<--- Sample 100% of available clients for evaluation\n",
    "        initial_parameters=params,        #<--- Initial model parameters\n",
    "        evaluate_fn=build_evaluate_fn(    #<--- Global evaluation function\n",
    "            exp_name = exp_name_, \n",
    "            base_type = base_type_,\n",
    "            data_name=data_name_, \n",
    "            experiment_item=experiment_name_, \n",
    "            num_labels=num_labels_\n",
    "            ),\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,  #<-- pass the metric aggregation function\n",
    "    )\n",
    "    \n",
    "    # Wrap the strategy with the DifferentialPrivacyServerSideFixedClipping wrapper\n",
    "    dp_strategy = DifferentialPrivacyClientSideAdaptiveClipping(\n",
    "        strategy= strategy,\n",
    "        noise_multiplier=10,\n",
    "        num_sampled_clients=fed_config.get(\"num_clients\"),\n",
    "        initial_clipping_norm = 500.0,\n",
    "        target_clipped_quantile = 0.09,\n",
    "        clip_norm_lr = 0.2,\n",
    "        clipped_count_stddev = 3 + fed_config.get(\"num_clients\")/20\n",
    "        )\n",
    "    \n",
    "    # Configure the server with the specified number of federated rounds\n",
    "    sever_config = ServerConfig(num_rounds=fed_config['num_rounds'])\n",
    "    \n",
    "    return ServerAppComponents(strategy = dp_strategy, config = sever_config)\n",
    "\n",
    "# Wrap the server function in a ServerApp, and instantiate it\n",
    "server = ServerApp(server_fn = server_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96eae912",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_setup = {\n",
    "    \"init_args\": {\n",
    "        \"logging_level\": ERROR, \n",
    "        \"log_to_driver\": fed_config.get(\"log_to_driver\")\n",
    "    },\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": fed_config.get(\"num_cpus\"), \n",
    "        \"num_gpus\": fed_config.get(\"num_gpus\")            \n",
    "    },\n",
    "}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\": \n",
    "    backend_setup[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834f1c1",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Initiate the Simulation \n",
    "\n",
    "Initiate the simulation by passing the server and client apps, and specify the number of supernodes that will be selected on every round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645681e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 13:27:36,646\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "2025-07-24 13:27:36,724\tINFO packaging.py:530 -- Creating a file package for local directory '/home/emeka/PrivacyBench'.\n",
      "2025-07-24 13:27:36,834\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_16f9835537e7adef.zip' (14.63MiB) to Ray cluster...\n",
      "2025-07-24 13:27:36,876\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_16f9835537e7adef.zip'.\n",
      "07/24/2025 13:27:37:DEBUG:Asyncio event loop already running.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: If not specified, `clipped_count_stddev` is set to `num_sampled_clients`/20 by default. This value (0.15) is too low to achieve the desired effective `noise_multiplier` (10). Consider increasing `clipped_count_stddev` or decreasing `noise_multiplier`.\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/server_app.py\", line 161, in __call__\n",
      "    components = self._server_fn(context)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/tmp/ipykernel_88637/2009366356.py\", line 38, in server_fn\n",
      "    dp_strategy = DifferentialPrivacyClientSideAdaptiveClipping(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/strategy/dp_adaptive_clipping.py\", line 356, in __init__\n",
      "    ) = compute_adaptive_noise_params(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/common/differential_privacy.py\", line 138, in compute_adaptive_noise_params\n",
      "    raise ValueError(\n",
      "ValueError: If not specified, `clipped_count_stddev` is set to `num_sampled_clients`/20 by default. This value (0.15) is too low to achieve the desired effective `noise_multiplier` (10). Consider increasing `clipped_count_stddev` or decreasing `noise_multiplier`.\n",
      "\n",
      "Exception in thread Thread-5 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emeka/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/emeka/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/simulation/run_simulation.py\", line 268, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/server_app.py\", line 161, in __call__\n",
      "    components = self._server_fn(context)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/tmp/ipykernel_88637/2009366356.py\", line 38, in server_fn\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/server/strategy/dp_adaptive_clipping.py\", line 356, in __init__\n",
      "    ) = compute_adaptive_noise_params(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emeka/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/common/differential_privacy.py\", line 138, in compute_adaptive_noise_params\n",
      "    raise ValueError(\n",
      "ValueError: If not specified, `clipped_count_stddev` is set to `num_sampled_clients`/20 by default. This value (0.15) is too low to achieve the desired effective `noise_multiplier` (10). Consider increasing `clipped_count_stddev` or decreasing `noise_multiplier`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      5\u001b[39m ray.init(\n\u001b[32m      6\u001b[39m     _temp_dir=\u001b[38;5;28mstr\u001b[39m(RAY_LOG_DIR),\n\u001b[32m      7\u001b[39m     runtime_env={\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     ignore_reinit_error=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m start_time = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfed_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_clients\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_setup\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m end_time = time.perf_counter()\n\u001b[32m     29\u001b[39m duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:211\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[32m    203\u001b[39m     warn_deprecated_feature_with_example(\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m         example_message=\u001b[33m\"\u001b[39m\u001b[33mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m _ = \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEventType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:510\u001b[39m, in \u001b[36m_run_simulation\u001b[39m\u001b[34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[39m\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[32m    507\u001b[39m         \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[32m    508\u001b[39m         logger = set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     updated_context = \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PrivacyBench/.venv/lib/python3.12/site-packages/flwr/simulation/run_simulation.py:408\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    406\u001b[39m         serverapp_th.join()\n\u001b[32m    407\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mException in ServerApp thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    410\u001b[39m log(DEBUG, \u001b[33m\"\u001b[39m\u001b[33mStopping Simulation Engine now.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[31mRuntimeError\u001b[39m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "project_root =  os.path.abspath(\"../..\")\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "    _temp_dir=str(RAY_LOG_DIR),\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            \"PYTHONWARNINGS\": \"ignore::DeprecationWarning\",  # More specific warning filter\n",
    "            \"OMP_NUM_THREADS\": \"1\"  # Prevents thread oversubscription\n",
    "        },\n",
    "        \"working_dir\": project_root,\n",
    "        'excludes': ['data', '.cache', '.docker', '.local', 'logs/model']\n",
    "    },\n",
    "    ignore_reinit_error=True\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "run_simulation(\n",
    "    server_app = server,\n",
    "    client_app = client,\n",
    "    num_supernodes = fed_config.get(\"num_clients\"),\n",
    "    backend_config=backend_setup\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "duration = end_time - start_time\n",
    "print(f\"\\nðŸ•’ Total Time: {duration // 60:.0f} min {duration % 60:.0f} sec\")\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f9774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacybench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
